{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第8章: 機械学習\n",
    "本章では，Bo Pang氏とLillian Lee氏が公開しているMovie Review Dataのsentence polarity dataset v1.0を用い，文を肯定的（ポジティブ）もしくは否定的（ネガティブ）に分類するタスク（極性分析）に取り組む．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 70. データの入手・整形\n",
    "文に関する極性分析の正解データを用い，以下の要領で正解データ（sentiment.txt）を作成せよ．\n",
    "\n",
    "1. rt-polarity.posの各行の先頭に\"+1 \"という文字列を追加する（極性ラベル\"+1\"とスペースに続けて肯定的な文の内容が続く）\n",
    "1. rt-polarity.negの各行の先頭に\"-1 \"という文字列を追加する（極性ラベル\"-1\"とスペースに続けて否定的な文の内容が続く）\n",
    "1. 上述1と2の内容を結合（concatenate）し，行をランダムに並び替える\n",
    "\n",
    "sentiment.txtを作成したら，正例（肯定的な文）の数と負例（否定的な文）の数を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正例: 5331件\n",
      "負例: 5331件\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def knock_70():\n",
    "    with codecs.open('../data/rt-polaritydata/rt-polarity.pos', 'r', 'cp1252') as f_pos:\n",
    "        df_pos = pd.concat([pd.DataFrame([['+1', sentence.rstrip('\\n')]]) for sentence in f_pos], ignore_index=True)        \n",
    "    with codecs.open('../data/rt-polaritydata/rt-polarity.neg', 'r', 'cp1252') as f_neg:\n",
    "        df_neg = pd.concat([pd.DataFrame([['-1', sentence.rstrip('\\n')]]) for sentence in f_neg], ignore_index=True)\n",
    "    df = pd.concat([df_pos, df_neg], ignore_index=True)\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    df.columns = ['Sentiment', 'Review']\n",
    "    df = df.reindex(np.random.permutation(df.index))\n",
    "    df.to_csv('../work/sentiment.txt', sep=' ', index=False)\n",
    "\n",
    "    print('正例: ' + str((df['Sentiment'] == '+1').sum()) + '件') \n",
    "    print('負例: ' + str((df['Sentiment'] == '-1').sum()) + '件')\n",
    "\n",
    "knock_70()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Review\r\n",
      "-1 \"to portray modern women the way director davis has done is just unthinkable . \"\r\n",
      "-1 \"kenneth branagh's energetic sweet-and-sour performance as a curmudgeonly british playwright grounds this overstuffed , erratic dramedy in which he and his improbably forbearing wife contend with craziness and child-rearing in los angeles . \"\r\n",
      "+1 \" . . . with \"\" the bourne identity \"\" we return to the more traditional action genre . \"\r\n",
      "+1 \"you can watch , giggle and get an adrenaline boost without feeling like you've completely lowered your entertainment standards . \"\r\n",
      "+1 \"fun , flip and terribly hip bit of cinematic entertainment . \"\r\n",
      "+1 \"fisher has bared his soul and confronted his own shortcomings here in a way . . . that feels very human and very true to life . \"\r\n",
      "+1 \"while the plot follows a predictable connect-the-dots course . . . director john schultz colors the picture in some evocative shades . \"\r\n",
      "-1 \"the impact of the armenian genocide is diluted by too much stage business in the modern day . \"\r\n",
      "+1 \"thanks to haynes' absolute control of the film's mood , and buoyed by three terrific performances , far from heaven actually pulls off this stylistic juggling act . \"\r\n",
      "+1 \"we know the plot's a little crazy , but it held my interest from start to finish . \"\r\n",
      "-1 \"half of it is composed of snappy patter and pseudo-sophisticated cultural observations , while the remainder . . . would be more at home on a daytime television serial . \"\r\n",
      "+1 \"though it lacks the utter authority of a genre gem , there's a certain robustness to this engaging mix of love and bloodletting . \"\r\n",
      "-1 \"some writer dude , i think his name was , uh , michael zaidan , was supposed to have like written the screenplay or something , but , dude , the only thing that i ever saw that was written down were the zeroes on my paycheck . \"\r\n",
      "+1 \"the film is small in scope , yet perfectly formed . \"\r\n",
      "-1 \"the plot plummets into a comedy graveyard before janice comes racing to the rescue in the final reel . \"\r\n",
      "-1 \"it's the movie equivalent of a sweaty old guy in a rain coat shopping for cheap porn . \"\r\n",
      "+1 \"it is a likable story , told with competence . \"\r\n",
      "-1 \"in the second half of the film , frei's control loosens in direct proportion to the amount of screen time he gives nachtwey for self-analysis . \"\r\n",
      "-1 \"[morgan] , judd and franklin can't save the script , rooted in a novel by joseph finder , from some opportunism . \"\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 20 ../work/sentiment.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 71. ストップワード\n",
    "英語のストップワードのリスト（ストップリスト）を適当に作成せよ．さらに，引数に与えられた単語（文字列）がストップリストに含まれている場合は真，それ以外は偽を返す関数を実装せよ．さらに，その関数に対するテストを記述せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_stop_word(word):\n",
    "    if not word:\n",
    "        return True\n",
    "    if len(word.rstrip()) <= 1:\n",
    "        return True\n",
    "    \n",
    "    STOP_WORD = set(\"\"\"\n",
    "    , . a an the at to on of for in by with above under\n",
    "    this that i you it he she they am are is was were \n",
    "    and but though although then so as \n",
    "    \" ' - – ( ) *\n",
    "    \"\"\".lower().split())\n",
    "    return word.lower() in STOP_WORD\n",
    "\n",
    "assert is_stop_word('a')\n",
    "assert is_stop_word('the')\n",
    "assert is_stop_word('i')\n",
    "assert is_stop_word('I')\n",
    "assert is_stop_word('YOU')\n",
    "assert is_stop_word('\"')\n",
    "assert is_stop_word('*')\n",
    "assert is_stop_word('')\n",
    "assert is_stop_word('　')\n",
    "assert is_stop_word(None)\n",
    "assert is_stop_word('e')\n",
    "\n",
    "assert not is_stop_word('good')\n",
    "assert not is_stop_word('bad')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 72. 素性抽出\n",
    "極性分析に有用そうな素性を各自で設計し，学習データから素性を抽出せよ．素性としては，レビューからストップワードを除去し，各単語をステミング処理したものが最低限のベースラインとなるであろう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元文\n",
      "['to portray modern women the way director davis has done is just unthinkable . ', \"kenneth branagh's energetic sweet-and-sour performance as a curmudgeonly british playwright grounds this overstuffed , erratic dramedy in which he and his improbably forbearing wife contend with craziness and child-rearing in los angeles . \"]\n",
      "\n",
      "マッピング\n",
      "['angel', 'branagh', 'british', 'child-rear', 'contend', 'crazi', 'curmudgeon', 'davi', 'director', 'done', 'dramedi', 'energet', 'errat', 'forbear', 'ground', 'has', 'his', 'improb', 'just', 'kenneth', 'los', 'modern', 'overstuf', 'perform', 'playwright', 'portray', 'sweet-and-sour', 'unthink', 'way', 'which', 'wife', 'women']\n",
      "\n",
      "素性\n",
      "[[ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.31622777  0.31622777  0.31622777  0.          0.          0.          0.\n",
      "   0.          0.31622777  0.          0.          0.31622777  0.          0.\n",
      "   0.31622777  0.          0.          0.          0.31622777  0.\n",
      "   0.31622777  0.31622777  0.          0.          0.31622777]\n",
      " [ 0.21320072  0.21320072  0.21320072  0.21320072  0.21320072  0.21320072\n",
      "   0.21320072  0.          0.          0.          0.21320072  0.21320072\n",
      "   0.21320072  0.21320072  0.21320072  0.          0.21320072  0.21320072\n",
      "   0.          0.21320072  0.21320072  0.          0.21320072  0.21320072\n",
      "   0.21320072  0.          0.21320072  0.          0.          0.21320072\n",
      "   0.21320072  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from stemming.porter2 import stem\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def stem_tokenizer(sentence):\n",
    "    return [stem(word) for word in sentence.split(' ') if not is_stop_word(word)]\n",
    "\n",
    "def extract_feature(text, min_df=1):\n",
    "    vectorizer = TfidfVectorizer(tokenizer=stem_tokenizer, min_df=min_df)\n",
    "    vectorizer = vectorizer.fit(text)\n",
    "    vector = vectorizer.transform(text)\n",
    "    return vectorizer, vector.toarray()\n",
    "\n",
    "def knock_72():\n",
    "    df = pd.read_csv('../work/sentiment.txt', sep=' ')\n",
    "    text = df['Review'].tolist()[:2]\n",
    "    vectorizer, feature = extract_feature(text)\n",
    "    print('元文')\n",
    "    print(text)\n",
    "    print('\\nマッピング')\n",
    "    print(vectorizer.get_feature_names())\n",
    "    print('\\n素性')\n",
    "    print(feature)\n",
    "\n",
    "knock_72()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 73. 学習\n",
    "72で抽出した素性を用いて，ロジスティック回帰モデルを学習せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy(train): 0.894144445933\n",
      "Accuracy(test): 0.764926539544\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "def learn_by_logistic_regression():\n",
    "    df = pd.read_csv('../work/sentiment.txt', sep=' ')\n",
    "    X = df['Review'].tolist()\n",
    "    y = df['Sentiment'].tolist()\n",
    "    vectorizer, feature = extract_feature(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(feature, y, test_size=0.3, shuffle=False)\n",
    "    \n",
    "    lr = LogisticRegression(solver='liblinear', random_state=0)\n",
    "    model = lr.fit(X_train, y_train)\n",
    "    print('Accuracy(train): ' + str(lr.score(X_train, y_train)))\n",
    "    print('Accuracy(test): ' + str(lr.score(X_test, y_test)))\n",
    "    \n",
    "    joblib.dump(model, '../work/model.pkl')\n",
    "    joblib.dump(vectorizer, '../work/vectorizer.pkl')\n",
    "\n",
    "learn_by_logistic_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 74. 予測\n",
    "73で学習したロジスティック回帰モデルを用い，与えられた文の極性ラベル（正例なら\"+1\"，負例なら\"-1\"）と，その予測確率を計算するプログラムを実装せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] [[ 0.3663977  0.6336023]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "def predict_by_logistic_regression(text):\n",
    "    lr = joblib.load('../work/model.pkl')\n",
    "    vectorizer = joblib.load('../work/vectorizer.pkl')\n",
    "    feature = vectorizer.transform([text]).toarray()\n",
    "    return lr.predict(feature), lr.predict_proba(feature)\n",
    "\n",
    "label, prob = predict_by_logistic_regression(\"to portray modern women the way director davis has done is just unthinkable . \")\n",
    "print(str(label) + ' ' + str(prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 75. 素性の重み\n",
    "73で学習したロジスティック回帰モデルの中で，重みの高い素性トップ10と，重みの低い素性トップ10を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 76. ラベル付け\n",
    "学習データに対してロジスティック回帰モデルを適用し，正解のラベル，予測されたラベル，予測確率をタブ区切り形式で出力せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 77. 正解率の計測\n",
    "76の出力を受け取り，予測の正解率，正例に関する適合率，再現率，F1スコアを求めるプログラムを作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 78. 5分割交差検定\n",
    "76-77の実験では，学習に用いた事例を評価にも用いたため，正当な評価とは言えない．すなわち，分類器が訓練事例を丸暗記する際の性能を評価しており，モデルの汎化性能を測定していない．そこで，5分割交差検定により，極性分類の正解率，適合率，再現率，F1スコアを求めよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 79. 適合率-再現率グラフの描画\n",
    "ロジスティック回帰モデルの分類の閾値を変化させることで，適合率-再現率グラフを描画せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
