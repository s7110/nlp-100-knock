{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第10章: ベクトル空間法 (II)\n",
    "第10章では，前章に引き続き単語ベクトルの学習に取り組む．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 90. word2vecによる学習\n",
    "81で作成したコーパスに対してword2vecを適用し，単語ベクトルを学習せよ．さらに，学習した単語ベクトルの形式を変換し，86-89のプログラムを動かせ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anarchism\r\n",
      "Anarchism is a political philosophy that advocates stateless societies often defined as self-governed voluntary institutions but that several authors have defined as more specific institutions based on non-hierarchical free associations Anarchism holds the state to be undesirable unnecessary or harmful While anti-statism is central anarchism entails opposing authority or hierarchical organisation in the conduct of human relations including but not limited to the state system\r\n",
      "As a subtle and anti-dogmatic philosophy anarchism draws on many currents of thought and strategy Anarchism does not offer a fixed body of doctrine from a single particular world view instead fluxing and flowing as a philosophy There are many types and traditions of anarchism not all of which are mutually exclusive Anarchist schools of thought can differ fundamentally supporting anything from extreme individualism to complete collectivism Strains of anarchism have often been divided into the categories of social and individualist anarchism or similar dual classifications Anarchism is usually considered a radical left-wing ideology and much of anarchist economics and anarchist legal philosophy reflect anti-authoritarian interpretations of communism collectivism syndicalism mutualism or participatory economics\r\n",
      "The central tendency of anarchism as a social movement has been represented by anarcho-communism and anarcho-syndicalism with individualist anarchism being primarily a literary phenomenon which nevertheless did have an impact on the bigger currents and individualists have also participated in large anarchist organisations Many anarchists oppose all forms of aggression supporting self-defense or non-violence anarcho-pacifism while others have supported the use of some coercive measures including violent revolution and propaganda of the deed as means to achieve anarchist ends\r\n",
      "Etymology and terminology\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 ../../chapter09/work/enwiki-20150112-400-r100-10576-compound_replaced.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import LineSentence, Word2Vec\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "sentences = LineSentence('../../chapter09/work/enwiki-20150112-400-r100-10576-compound_replaced.txt')\n",
    "model = Word2Vec(sentences, size=100, window=5, min_count=10, sg=1, hs=0, negative=5, workers=4)\n",
    "model.save('../work/word2vec_d100_w5_sg.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United_States の単語ベクトル:\n",
      "[-0.28676808 -0.33307534 -0.34927177  0.3465644   0.04432601 -0.4322733\n",
      "  0.371253   -0.8625143   0.21403056  0.33887684  0.24313676 -0.01577393\n",
      " -0.77665657  0.3739606  -0.24772237 -0.16604081 -0.13625292  0.12585013\n",
      " -0.42808485 -0.05091853 -0.7095111  -0.4920803  -0.12442167  0.4092078\n",
      "  0.15587461  0.1395456   0.22662784  0.06617327  0.02785342  0.4088276\n",
      "  0.20289661  0.37518272 -0.29654968  0.46529588 -0.05565928 -0.36331254\n",
      "  0.18550792 -0.33341426 -0.19583142  0.16085361 -0.28075716  0.3405469\n",
      "  0.3248612  -0.00649171  0.4347056  -0.05338414  0.12131537  0.03553332\n",
      " -0.14288971  0.3956565  -0.05746122 -0.3386314   0.07332081 -0.29849255\n",
      "  0.5082681   0.30424362  0.34834433  0.2770656  -0.43447274 -0.03748158\n",
      "  0.42596143 -0.26388896  0.53265697  0.17335704 -0.5438138   0.44658875\n",
      "  0.24118969 -0.17824431  0.09972241 -0.19586906 -0.03400543  0.20292345\n",
      " -0.10313662 -0.11593749 -0.13695014  0.17198503 -0.00220675 -0.38764527\n",
      "  0.20446423 -0.105957    0.0373738   0.14362906 -0.58369374 -0.24909882\n",
      "  0.5885701   0.21878438  0.49005327  0.12667277 -0.18156478 -0.22958118\n",
      "  0.17392318  0.17961998 -0.12852581 -0.3138584  -0.08763295 -0.10307328\n",
      "  0.24873328  0.7418293  -0.26185557  0.33419707]\n",
      "\n",
      "United_States と U.S の類似度:\n",
      "0.90501493\n",
      "\n",
      "England と類似度の高い単語10件\n",
      "[('Scotland', 0.846195638179779), ('Wales', 0.8299583196640015), ('Somerset', 0.7749377489089966), ('Ireland', 0.7565882205963135), ('Cornwall', 0.7307652235031128), ('Australia', 0.7248743176460266), ('Perth', 0.715800940990448), ('Essex', 0.7133100628852844), ('New_Zealand', 0.711432933807373), ('Cheshire', 0.7083759307861328)]\n",
      "\n",
      "Spain - Madrid + Athens と類似度の高い単語10件\n",
      "[('Denmark', 0.6744471192359924), ('Greece', 0.6714252829551697), ('Latvia', 0.6694968342781067), ('Norway', 0.6652658581733704), ('Sweden', 0.6628214120864868), ('Romania', 0.6603386402130127), ('Scandinavia', 0.6364423036575317), ('Egypt', 0.633529543876648), ('Slovakia', 0.628932535648346), ('Yugoslavia', 0.6285340785980225)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "def knock_90():\n",
    "    model = Word2Vec.load(\"../work/word2vec_d100_w5_sg.model\")\n",
    "    print(\"United_States の単語ベクトル:\")\n",
    "    print(model.wv[\"United_States\"])\n",
    "    \n",
    "    print(\"\\nUnited_States と U.S の類似度:\")\n",
    "    print(model.wv.similarity(\"United_States\", \"U.S\"))\n",
    "\n",
    "    print(\"\\nEngland と類似度の高い単語10件\")\n",
    "    print(model.wv.most_similar(positive=['England'], topn=10))\n",
    "    \n",
    "    print(\"\\nSpain - Madrid + Athens と類似度の高い単語10件\")\n",
    "    print(model.wv.most_similar(positive=[\"Spain\", \"Athens\"], negative=[\"Madrid\"], topn=10))\n",
    "    \n",
    "knock_90()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 91. アナロジーデータの準備\n",
    "単語アナロジーの評価データをダウンロードせよ．このデータ中で\": \"で始まる行はセクション名を表す．例えば，\": capital-common-countries\"という行は，\"capital-common-countries\"というセクションの開始を表している．ダウンロードした評価データの中で，\"family\"というセクションに含まれる評価事例を抜き出してファイルに保存せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knock_91():\n",
    "    with open(\"../data/questions-words.txt\") as f_in, open(\"../work/questions-words-family.txt\", \"w\") as f_out:\n",
    "        is_family = False\n",
    "        for line in f_in:\n",
    "            if line.startswith(\": family\"):\n",
    "                is_family = True\n",
    "                continue\n",
    "            if line.startswith(\": \") and is_family:\n",
    "                break\n",
    "            if is_family:\n",
    "                f_out.write(line)\n",
    "\n",
    "knock_91()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 92. アナロジーデータへの適用\n",
    "91で作成した評価データの各事例に対して，vec(2列目の単語) - vec(1列目の単語) + vec(3列目の単語)を計算し，そのベクトルと類似度が最も高い単語と，その類似度を求めよ．求めた単語と類似度は，各事例の末尾に追記せよ．このプログラムを85で作成した単語ベクトル，90で作成した単語ベクトルに対して適用せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from functools import lru_cache\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "with open('../../chapter09/work/word_vector.pkl', 'rb') as f:\n",
    "    word_vectors_85 = pickle.load(f)\n",
    "with open('../../chapter09/work/word_to_index.pkl', 'rb') as f:\n",
    "    word_to_index_85 = pickle.load(f)\n",
    "\n",
    "model_90 = Word2Vec.load(\"../work/word2vec_d100_w5_sg.model\")\n",
    "    \n",
    "def get_similar_word_and_vector_knock_85(base_word, minus_word, plus_word):\n",
    "    \n",
    "    @lru_cache(maxsize=100)\n",
    "    def get_word_vector(word):\n",
    "        return word_vectors_85[word_to_index_85[word.lower()]]\n",
    "    \n",
    "    base_word_vector = get_word_vector(base_word.lower())\n",
    "    minus_word_vector = get_word_vector(minus_word.lower())\n",
    "    plus_word_vector = get_word_vector(plus_word.lower())\n",
    "    target_vector = base_word_vector - minus_word_vector + plus_word_vector\n",
    "    cosine_similarities = { word:cosine_similarity([target_vector],[word_vectors_85[index]])[0][0] for word,index in word_to_index_85.items()}\n",
    "    return sorted(cosine_similarities.items(), key=lambda x:x[1], reverse=True)[0]\n",
    "\n",
    "def get_similar_word_and_vector_knock_90(base_word, minus_word, plus_word):\n",
    "    try:\n",
    "        return model_90.wv.most_similar(positive=[base_word, plus_word], negative=[minus_word], topn=1)[0]\n",
    "    except KeyError:\n",
    "        return \"UNK\", 0.0\n",
    "\n",
    "def knock_92():\n",
    "    with open(\"../work/questions-words-family.txt\") as f_in, open(\"../work/questions-words-family-85.txt\", \"w\") as f_out_85, open(\"../work/questions-words-family-90.txt\", \"w\") as f_out_90:\n",
    "        for line in f_in:\n",
    "            minus, base, plus, answer = line.rstrip().split()\n",
    "            pred_word_85, pred_similarity_85 = get_similar_word_and_vector_knock_85(base, minus, plus)\n",
    "            pred_word_90, pred_similarity_90 = get_similar_word_and_vector_knock_90(base, minus, plus)\n",
    "            f_out_85.write(\" \".join([minus, base, plus, answer, pred_word_85, str(pred_similarity_85)]).rstrip() + \"\\n\")\n",
    "            f_out_90.write(\" \".join([minus, base, plus, answer, pred_word_90, str(pred_similarity_90)]).rstrip() + \"\\n\")\n",
    "            \n",
    "knock_92()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 5 ../work/questions-words-family-85.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 5 ../work/questions-words-family-90.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 93. アナロジータスクの正解率の計算\n",
    "92で作ったデータを用い，各モデルのアナロジータスクの正解率を求めよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calc_accuracy(file_path):\n",
    "    df = pd.read_csv(file_path, names=(\"minus\", \"base\", \"plus\", \"answer\", \"pred\", \"similarity\"), delim_whitespace=True)\n",
    "    answer_list = list(df[\"answer\"])\n",
    "    pred_list = list(df[\"pred\"])\n",
    "    return sum(1 for pred, answer in zip(pred_list,answer_list) if pred == answer) / float(len(pred_list))\n",
    "    \n",
    "def konck_93():\n",
    "    print(\"正解率 (Word2Vec): \") + str(calc_accuracy(\"../work/questions-words-family-90.txt\"))\n",
    "    print(\"正解率 (PMI)\": ) + str(calc_accuracy(\"../work/questions-words-family-85.txt\"))\n",
    "    \n",
    "knock_93()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 94. WordSimilarity-353での類似度計算\n",
    "The WordSimilarity-353 Test Collectionの評価データを入力とし，1列目と2列目の単語の類似度を計算し，各行の末尾に類似度の値を追加するプログラムを作成せよ．このプログラムを85で作成した単語ベクトル，90で作成した単語ベクトルに対して適用せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 95. WordSimilarity-353での評価\n",
    "94で作ったデータを用い，各モデルが出力する類似度のランキングと，人間の類似度判定のランキングの間のスピアマン相関係数を計算せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 96. 国名に関するベクトルの抽出\n",
    "word2vecの学習結果から，国名に関するベクトルのみを抜き出せ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 97. k-meansクラスタリング\n",
    "96の単語ベクトルに対して，k-meansクラスタリングをクラスタ数k=5として実行せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 98. Ward法によるクラスタリング\n",
    "96の単語ベクトルに対して，Ward法による階層型クラスタリングを実行せよ．さらに，クラスタリング結果をデンドログラムとして可視化せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 99. t-SNEによる可視化\n",
    "96の単語ベクトルに対して，ベクトル空間をt-SNEで可視化せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
